# NILAY1556

## Exploring...
- **Diffusion Models & RoPE** (19-08-25)
  Understanding diffusion models as the state-of-the-art in generative AI, surpassing previous leaders like VAEs and GANs, and exploring Rotary Positional Embedding (RoPE) for enhanced sequence processing.

- **Transformer Limitations & Solutions** (30-07-25)
  Analyzes Transformer limitations, including quadratic memory complexity, diminishing returns with large context windows, and struggles with reasoning tasks, while highlighting solutions like sparse attention, low-rank approximation, Flash Attention, data biasing, selective attention (MEGA, LaMDA, CEMA), and Chain-of-Thought for symbolic reasoning.

- **Exploring AI & LLM Projects** (29-07-25)
  Review of Google DeepMind's Opal project and exploration of GitHub repositories including Graphrag Toolkit and Awesome LLM Apps, focusing on AI and Large Language Model applications.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21
- Starred [osmandkitay/aura](https://github.com/osmandkitay/aura) on 2025-08-07

## Forked Repositories
- Forked [osmandkitay/aura](https://github.com/NILAY1556/aura) on 2025-08-07

