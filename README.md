# NILAY1556

## Exploring...
- **Diffusion Models and RoPE** (19-08-25)
  Explores diffusion models as the current state-of-the-art, surpassing previous approaches like VAEs and GANs, and introduces Rotary Positional Embedding (RoPE).

- **Transformer Limitations and Solutions** (30-07-25)
  Explores key Transformer limitations: quadratic memory complexity (addressed by sparse/approximate attention, Flash Attention), diminishing returns with large context (mitigated by recency bias like MEGA, selective attention like LaMDA/CEMA), and reasoning limitations (addressed by Chain-of-Thought).

- **Google DeepMind's Opal** (29-07-25)
  Explored Google DeepMind's new Opal project and reviewed key GitHub repositories including Graphrag Toolkit and Awesome LLM Apps, focusing on advancements in AI and LLM applications.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [miurla/morphic](https://github.com/miurla/morphic) on 2025-09-09
- Starred [The-Pocket/PocketFlow-Tutorial-Video-Generator](https://github.com/The-Pocket/PocketFlow-Tutorial-Video-Generator) on 2025-09-08
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21

## Forked Repositories
- Forked [miurla/morphic](https://github.com/NILAY1556/morphic) on 2025-09-09

