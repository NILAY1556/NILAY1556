# NILAY1556

## Exploring...
- **Transformer Limitations & Solutions** (30-07-25)
  Analyzes Transformer limitations: quadratic memory complexity solvable by sparse attention or FlashAttention; diminishing returns with large contexts addressed by biasing recent data (MEGA) or selective attention (LaMDA, CEMA); and reasoning task deficits overcome by techniques like Chain-of-Thought (CoT).

- **Exploring AI & LLM Projects** (29-07-25)
  Reviewed Google DeepMind's Opal project and key GitHub repositories like graphrag-toolkit and awesome-llm-apps for LLM applications.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

- **DiffusionLM Architecture Explained** (28-07-25)
  Explores DiffusionLM architecture, detailing its components and concepts through two key research papers: LaViDa and MMaDA, which describe the overall system.
  [LaViDa](https://arxiv.org/abs/2505.16839)
  [MMaDA](https://arxiv.org/abs/2505.15809)

## Starred Repositories
- Starred [osmandkitay/aura](https://github.com/osmandkitay/aura) on 2025-08-07
- Starred [sapientinc/HRM](https://github.com/sapientinc/HRM) on 2025-07-27
- Starred [universal-tool-calling-protocol/python-utcp](https://github.com/universal-tool-calling-protocol/python-utcp) on 2025-07-15

## Forked Repositories
- Forked [osmandkitay/aura](https://github.com/NILAY1556/aura) on 2025-08-07
- Forked [sapientinc/HRM](https://github.com/NILAY1556/HRM) on 2025-07-27
- Forked [mem0ai/mem0-mcp](https://github.com/NILAY1556/mem0-mcp) on 2025-07-15

