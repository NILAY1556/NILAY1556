# NILAY1556

## Exploring...
- **Diffusion Models and RoPE** (19-08-25)
  Explores diffusion models as state-of-the-art generative AI, surpassing previous GAN and VAE-based latent space approaches, and introduces Rotary Positional Embedding (RoPE) for enhanced sequence processing.

- **Transformer Limitations and Solutions** (30-07-25)
  This content explores key limitations of Transformer models, including: quadratic memory complexity (addressed by sparse attention, low-rank approximation, and Flash Attention); diminishing returns with large context windows (mitigated by biasing recent data, weight updates like MEGA, and selective attention like LaMDA/CEMA); and challenges in reasoning tasks (where statistical correlation is strong but symbolic thinking requires approaches like Chain-of-Thought).

- **DeepMind Opal & LLM Repos** (29-07-25)
  Explored Google DeepMind's Opal project, alongside key GitHub repositories for LLM applications including Graphrag Toolkit and Awesome-LLM-Apps.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [miurla/morphic](https://github.com/miurla/morphic) on 2025-09-09
- Starred [The-Pocket/PocketFlow-Tutorial-Video-Generator](https://github.com/The-Pocket/PocketFlow-Tutorial-Video-Generator) on 2025-09-08

## Forked Repositories
- Forked [miurla/morphic](https://github.com/NILAY1556/morphic) on 2025-09-09

