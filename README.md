# NILAY1556

## Exploring...
- **Diffusion Models and RoPE** (19-08-25)
  This content introduces diffusion models, highlighting their superiority over previous state-of-the-art methods like VAEs and GANs, and explores the application of RoPE (Rotary Positional Embedding) within this domain.

- **Transformer Limitations and Solutions** (30-07-25)
  Analysis of Transformer limitations including quadratic memory complexity, diminishing returns with large context windows, and challenges with reasoning tasks. Explores solutions such as sparse attention, low-rank approximation, Flash Attention, biasing towards recent data (MEGA), selective attention (LaMDA, CEMA), and Chain-of-Thought (CoT) prompting.

- **Exploring LLM Projects & Tools** (29-07-25)
  Reviewed Google DeepMind's Opal project and explored key GitHub repositories for Large Language Model applications, including the Graphrag Toolkit.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [miurla/morphic](https://github.com/miurla/morphic) on 2025-09-09
- Starred [The-Pocket/PocketFlow-Tutorial-Video-Generator](https://github.com/The-Pocket/PocketFlow-Tutorial-Video-Generator) on 2025-09-08
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21

## Forked Repositories
- Forked [miurla/morphic](https://github.com/NILAY1556/morphic) on 2025-09-09

