# NILAY1556

## Exploring...
- **Transformer Limitations & Solutions** (30-07-25)
  Explores Transformer limitations including quadratic memory complexity, addressed by sparse/approximate attention and Flash Attention. Discusses diminishing returns with large context windows via recency bias and selective attention. Also covers reasoning task limitations, highlighting statistical correlation over symbolic thought, and the introduction of CoT.

- **Exploring AI & LLM Projects** (29-07-25)
  Reviewed Google DeepMind's Opal project and explored GitHub repositories for Graphrag Toolkit and awesome LLM applications.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

- **DiffusionLM Architecture Explained** (28-07-25)
  Explores DiffusionLM, a hyped language model technology from Google DeepMind, detailing its architecture through the LaViDa and MMaDA research papers.
  [LaViDa](https://arxiv.org/abs/2505.16839)
  [MMaDA](https://arxiv.org/abs/2505.15809)

## Starred Repositories
- Starred [osmandkitay/aura](https://github.com/osmandkitay/aura) on 2025-08-07
- Starred [sapientinc/HRM](https://github.com/sapientinc/HRM) on 2025-07-27
- Starred [universal-tool-calling-protocol/python-utcp](https://github.com/universal-tool-calling-protocol/python-utcp) on 2025-07-15

## Forked Repositories
- Forked [osmandkitay/aura](https://github.com/NILAY1556/aura) on 2025-08-07
- Forked [sapientinc/HRM](https://github.com/NILAY1556/HRM) on 2025-07-27
- Forked [mem0ai/mem0-mcp](https://github.com/NILAY1556/mem0-mcp) on 2025-07-15

