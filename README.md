# NILAY1556

## Exploring...
- **Diffusion Models: SoTA** (19-08-25)
  Explores diffusion models, a state-of-the-art approach in generative AI, contrasting them with previous leaders like VAEs and GANs in latent space.

- **Transformer Limitations and Solutions** (30-07-25)
  This content explores the limitations of Transformers, including quadratic memory complexity, diminishing returns with large context windows, and challenges in reasoning tasks, and discusses solutions like sparse attention, low-rank approximation, Flash Attention, biasing toward recent data, selective attention patterns, and Chain-of-Thought prompting.

- **Exploring AI Projects and Tools** (29-07-25)
  Reviewed Google DeepMind's Opal project and explored GitHub repositories for LLM applications, including the GraphRag Toolkit, gaining insights into practical AI development and tools.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21

