# NILAY1556

## Exploring...
- **Understanding Diffusion Models** (19-08-25)
  This learning content introduces RoPE (Rotary Positional Embedding) and explores diffusion models, which have surpassed VAEs and GANs as the state-of-the-art approach for generative tasks by leveraging latent space concepts.

- **Transformer Limitations and Solutions** (30-07-25)
  Explores transformer limitations: quadratic memory complexity addressed by sparse attention, low-rank approximation, and FlashAttention. Discusses diminishing returns with large context windows via biasing recent data (MEGA) or selective attention (LaMDA, CEMA). Highlights limitations in reasoning tasks, where statistical correlation is strong, but symbolic thinking and Chain-of-Thought (CoT) are needed.

- **Exploring LLM Projects and Tools** (29-07-25)
  This content reviews Google DeepMind's Opal project and explores valuable GitHub repositories such as graphrag-toolkit and awesome-llm-apps, offering insights into current LLM development.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21

