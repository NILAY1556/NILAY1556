# NILAY1556

## Exploring...
- **Understanding Diffusion Models** (19-08-25)
  Explores Diffusion Models, highlighting their advancement beyond latent space, VAEs, and GANs, and introduces Rotary Positional Embedding (RoPE) as a key technology.

- **Transformer Limitations & Solutions** (30-07-25)
  Analysis of Transformer limitations including quadratic memory complexity, diminishing returns with large context windows, and reasoning challenges. Solutions discussed are sparse attention, low-rank approximation, Flash Attention, biasing on recent data (MEGA), selective attention (LaMDA, CEMA), and the role of Chain-of-Thought (CoT) for reasoning.

- **Exploring AI Projects** (29-07-25)
  Reviewed Google DeepMind's Opal, a new project. Also explored GitHub repositories like Graphrag Toolkit and Awesome LLM Apps, focusing on graph-based and general LLM applications.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21
- Starred [osmandkitay/aura](https://github.com/osmandkitay/aura) on 2025-08-07

## Forked Repositories
- Forked [osmandkitay/aura](https://github.com/NILAY1556/aura) on 2025-08-07

