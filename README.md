# NILAY1556

## Exploring...
- **Understanding Diffusion and RoPE** (19-08-25)
  Learn about Diffusion models, which have surpassed VAEs and GANs as state-of-the-art, and explore Rotary Positional Embedding (RoPE).

- **Transformer Limitations and Solutions** (30-07-25)
  Analyzing Transformer limitations, including quadratic memory complexity (addressed by sparse/approximate attention like Flash Attention) and diminishing returns with large context windows (mitigated by biasing recent data, selective attention in MEGA/LaMDA/CEMA). Also discusses their statistical correlation strength versus reasoning/symbolic thinking, leading to approaches like Chain-of-Thought (CoT).

- **Exploring AI & LLM Projects** (29-07-25)
  Reviewed Google DeepMind's Opal project and valuable GitHub repositories including Graphrag Toolkit and Awesome-LLM-Apps for insights into AI and LLM applications.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21
- Starred [osmandkitay/aura](https://github.com/osmandkitay/aura) on 2025-08-07
- Starred [sapientinc/HRM](https://github.com/sapientinc/HRM) on 2025-07-27

## Forked Repositories
- Forked [osmandkitay/aura](https://github.com/NILAY1556/aura) on 2025-08-07
- Forked [sapientinc/HRM](https://github.com/NILAY1556/HRM) on 2025-07-27

