# NILAY1556

## Exploring...
- **Understanding Diffusion Models** (19-08-25)
  Explore Diffusion Models, which are now state-of-the-art, contrasting with previous leaders like VAEs and GANs. Learn about their latent space and how they've surpassed traditional generative models.

- **Transformer Limitations and Solutions** (30-07-25)
  Explores Transformer limitations including quadratic memory complexity, solved by techniques like FlashAttention. Addresses diminishing returns with large contexts via recency bias (MEGA) and selective attention (LaMDA, CEMA). Discusses Transformer's statistical correlation strength versus symbolic reasoning, leading to Chain-of-Thought (CoT).

- **Exploring AI Projects and Tools** (29-07-25)
  Reviewed Google DeepMind's Opal project and curated GitHub repositories including Graphrag Toolkit and Awesome LLM Apps, focusing on practical AI applications and resources.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21
- Starred [osmandkitay/aura](https://github.com/osmandkitay/aura) on 2025-08-07
- Starred [sapientinc/HRM](https://github.com/sapientinc/HRM) on 2025-07-27

## Forked Repositories
- Forked [osmandkitay/aura](https://github.com/NILAY1556/aura) on 2025-08-07
- Forked [sapientinc/HRM](https://github.com/NILAY1556/HRM) on 2025-07-27

