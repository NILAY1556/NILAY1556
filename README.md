# NILAY1556

## Exploring...
- **Understanding Diffusion and RoPE** (19-08-25)
  Explore diffusion models, the current state-of-the-art surpassing VAEs and GANs in latent space, and Rotary Positional Embedding (RoPE) for enhanced transformer performance.

- **Transformer Limitations & Solutions** (30-07-25)
  Explores transformer limitations including quadratic memory complexity (addressed by sparse attention, low-rank approximation, and FlashAttention) and diminishing returns with large context windows (managed by biasing recent data, weight updates like MEGA, or selective attention like LaMDA/CEMA). Also notes transformers excel at statistical correlation but struggle with reasoning tasks, leading to approaches like Chain-of-Thought (CoT).

- **Opal, Graphrag, LLM Apps** (29-07-25)
  Reviewed Google DeepMind's Opal project and explored GitHub repositories for Graphrag Toolkit and Awesome LLM Apps, gaining insights into advanced AI tools and applications.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [osmandkitay/aura](https://github.com/osmandkitay/aura) on 2025-08-07
- Starred [sapientinc/HRM](https://github.com/sapientinc/HRM) on 2025-07-27

## Forked Repositories
- Forked [osmandkitay/aura](https://github.com/NILAY1556/aura) on 2025-08-07
- Forked [sapientinc/HRM](https://github.com/NILAY1556/HRM) on 2025-07-27

