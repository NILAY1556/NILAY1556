# NILAY1556

## Exploring...
- **Diffusion Models and RoPE** (19-08-25)
  This content explores Diffusion Models, identifying them as the current state-of-the-art (SoTA) in contrast to earlier methods like VAEs and GANs which operated in latent space. It also introduces Rotary Positional Embedding (RoPE).

- **Transformer Limitations and Solutions** (30-07-25)
  Explores Transformer limitations including quadratic memory complexity (addressable by sparse attention, low-rank approximation, and FlashAttention), diminishing returns with large context windows (mitigated by biasing recent data, weight updates, or selective attention like MEGA, LaMDA, and CEMA), and reasoning task challenges. Transformers excel at token correlation but struggle with symbolic thinking, leading to the development of techniques like Chain-of-Thought (CoT).

- **Exploring AI Tools & Projects** (29-07-25)
  Reviewed Google DeepMind's Opal project, along with notable GitHub repositories such as graphrag-toolkit and awesome-llm-apps, gaining insights into current AI development.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [miurla/morphic](https://github.com/miurla/morphic) on 2025-09-09
- Starred [The-Pocket/PocketFlow-Tutorial-Video-Generator](https://github.com/The-Pocket/PocketFlow-Tutorial-Video-Generator) on 2025-09-08
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21

## Forked Repositories
- Forked [miurla/morphic](https://github.com/NILAY1556/morphic) on 2025-09-09

