# NILAY1556

## Exploring...
- **Understanding RoPE and Diffusion** (19-08-25)
  Explores Rotary Positional Embedding (RoPE) and the rise of diffusion models, highlighting their advancements over previous generative techniques like VAEs and GANs.

- **Transformer Limitations & Solutions** (30-07-25)
  Analyzes Transformer limitations including quadratic memory complexity (addressed by sparse/approximate attention like FlashAttention) and diminishing returns with large context windows (mitigated by recency bias like MEGA or selective attention like LaMDA/CEMA). Also discusses limitations in reasoning tasks compared to statistical correlation, leading to approaches like Chain-of-Thought.

- **DeepMind's Opal and LLM Toolkit** (29-07-25)
  Reviewed Google DeepMind's Opal project and explored GitHub repositories including Graphrag-Toolkit and Awesome-LLM-Apps to understand emerging LLM applications.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21
- Starred [osmandkitay/aura](https://github.com/osmandkitay/aura) on 2025-08-07
- Starred [sapientinc/HRM](https://github.com/sapientinc/HRM) on 2025-07-27

## Forked Repositories
- Forked [osmandkitay/aura](https://github.com/NILAY1556/aura) on 2025-08-07
- Forked [sapientinc/HRM](https://github.com/NILAY1556/HRM) on 2025-07-27

