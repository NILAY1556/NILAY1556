# NILAY1556

## Exploring...
- **Diffusion Models and RoPE** (19-08-25)
  Learn about diffusion models, which have surpassed VAEs and GANs as the state-of-the-art in generative AI, and understand Rotary Positional Embedding (RoPE) for enhanced context.

- **Transformer Limitations and Solutions** (30-07-25)
  This content analyzes limitations of Transformer models, including: quadratic memory complexity (addressed by sparse attention, low-rank approximation, and Flash Attention), diminishing returns with large context windows (managed via recency biasing like MEGA, selective attention like LaMDA/CEMA), and reasoning tasks (where statistical correlation is strong but symbolic thinking requires approaches like Chain-of-Thought).

- **Review of AI Projects** (29-07-25)
  Reviewed Google DeepMind's Opal project and explored key GitHub repositories including graphrag-toolkit and awesome-llm-apps, focusing on AI application development.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [The-Pocket/PocketFlow-Tutorial-Video-Generator](https://github.com/The-Pocket/PocketFlow-Tutorial-Video-Generator) on 2025-09-08
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21

