# NILAY1556

## Exploring...
- **Diffusion Models Explained** (19-08-25)
  Understanding diffusion models, their latent space, and how they have surpassed VAEs and GANs as state-of-the-art generative models, alongside an introduction to Rotary Positional Embedding (RoPE).

- **Transformer Limitations and Solutions** (30-07-25)
  Analysis of Transformer limitations including quadratic memory complexity, diminishing returns with large context windows, and challenges in reasoning tasks. Discusses solutions like sparse attention, low-rank approximation, Flash Attention, biasing towards recent data (MEGA), selective attention (LaMDA, CEMA), and Chain-of-Thought (CoT) prompting.

- **Exploring AI Projects and Tools** (29-07-25)
  Reviewed Google DeepMind's Opal project. Explored key GitHub repositories including GraphRag Toolkit and Awesome LLM Apps, providing insights into prominent AI applications and development resources.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21
- Starred [osmandkitay/aura](https://github.com/osmandkitay/aura) on 2025-08-07

## Forked Repositories
- Forked [osmandkitay/aura](https://github.com/NILAY1556/aura) on 2025-08-07

