# NILAY1556

## Exploring...
- **Diffusion Models and RoPE** (19-08-25)
  Explores diffusion models, highlighting their state-of-the-art performance surpassing VAEs and GANs, and introduces Rotary Positional Embedding (RoPE) as a key component in their architecture.

- **Transformer Limitations and Solutions** (30-07-25)
  Analysis of Transformer limitations including quadratic memory complexity, diminishing returns with large context windows, and reasoning challenges. Explores solutions like sparse attention, low-rank approximation, Flash Attention, MEGA, LaMDA, CEMA, and Chain-of-Thought (CoT) for improved performance.

- **AI Project & Repo Exploration** (29-07-25)
  Explored Google DeepMind's Opal project and reviewed key GitHub repositories for LLM applications, including the graphrag-toolkit.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21
- Starred [osmandkitay/aura](https://github.com/osmandkitay/aura) on 2025-08-07

## Forked Repositories
- Forked [osmandkitay/aura](https://github.com/NILAY1556/aura) on 2025-08-07

