# NILAY1556

## Exploring...
- **Understanding RoPE & Diffusion Models** (19-08-25)
  This learning content covers Rotary Positional Embedding (RoPE) and the advancement of Diffusion models, which have become state-of-the-art, surpassing previous leaders like VAEs and GANs in the latent space.

- **Transformer Limitations & Solutions** (30-07-25)
  Analyzes Transformer limitations including quadratic memory complexity, diminishing returns with large context windows, and reasoning task challenges. Discusses solutions like sparse/approximate attention (FlashAttention), biasing recent data/selective attention (MEGA, LaMDA, CEMA), and the need for Chain-of-Thought (CoT) for symbolic reasoning.

- **Exploring AI Projects and Tools** (29-07-25)
  Reviewed Google DeepMind's Opal project and beneficial GitHub repositories including GraphRag Toolkit and Awesome LLM Apps for AI development insights.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [Growth-Kinetics/DiffMem](https://github.com/Growth-Kinetics/DiffMem) on 2025-08-21
- Starred [osmandkitay/aura](https://github.com/osmandkitay/aura) on 2025-08-07

## Forked Repositories
- Forked [osmandkitay/aura](https://github.com/NILAY1556/aura) on 2025-08-07

