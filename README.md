# NILAY1556

## Exploring...
- **Diffusion Models and RoPE** (19-08-25)
  This learning content introduces diffusion models as the current state-of-the-art in generative AI, surpassing previous methods like VAEs and GANs. It also covers Rotary Positional Embedding (RoPE), a key technology for positional encoding in transformer models.

- **Transformer Limitations and Solutions** (30-07-25)
  This content analyzes transformer limitations including quadratic memory complexity, diminishing returns with large context windows, and challenges in reasoning tasks. Solutions discussed are FlashAttention for memory, biasing recent data (MEGA) or selective attention (LaMDA, CEMA) for context, and Chain-of-Thought (CoT) for reasoning.

- **AI Projects & Tools Review** (29-07-25)
  Reviewed Google DeepMind's Opal project and notable GitHub repositories: Graphrag Toolkit and Awesome LLM Apps, exploring key AI technologies and applications.
  [opal](https://opal.withgoogle.com/)
  [graphrag-toolkit](https://github.com/awslabs/graphrag-toolkit)

## Starred Repositories
- Starred [toon-format/toon](https://github.com/toon-format/toon) on 2025-10-29
- Starred [alankbi/detecto](https://github.com/alankbi/detecto) on 2025-10-27
- Starred [google-deepmind/randomized_positional_encodings](https://github.com/google-deepmind/randomized_positional_encodings) on 2025-10-27
- Starred [BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM) on 2025-10-27
- Starred [facebookresearch/detectron2](https://github.com/facebookresearch/detectron2) on 2025-10-27

